Understanding huffduff-video bandwidth usage

As of 2015-04-29, [huffduff-video](/2015-03-07_huffduff-video) is serving ~257
GB/mo via S3, which costs ~$24/mo in bandwidth. I'm ok with that, but it could
probably be lower.

As always, measure first, then optimize. I turned on
[S3 access logging](http://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html),
waited 24h, then ran these commands to collect and aggregate the logs to see
who's downloading these files:

    aws --profile personal s3 sync s3://huffduff-video/logs .
    grep REST.GET.OBJECT 2015-* | grep ' 200 ' | cut -d' ' -f8,20- \
      | sort | uniq -c | sort -n -r > user_agents

This gave me some useful baseline numbers. Over a 24h period, there were 482
downloads, 318 of which came from bots. (That's 2/3!) Looking at the top user
agents by downloads, five out of six were bots. The sixth was the
[Overcast](http://overcast.fm/) podcast app.

* [Flipboard](https://flipboard.com/)Proxy (142 downloads)
* [Googlebot](http://www.google.com/bot.html) (67)
* [Twitterbot](https://dev.twitter.com/cards/getting-started#crawling) (39)
* [Overcast](http://overcast.fm/) (47)
* [Yahoo! Slurp](http://help.yahoo.com/help/us/ysearch/slurp) (36)
* [Googlebot-Video](https://support.google.com/webmasters/answer/1061943) (34)

(Side note: Googlebot-Video is polite and includes `Etag` or `If-Modified-Since`
when it refetches files. It sent 68 requests, but exactly half of those resulted
in an empty `304` response. Thanks Googlebot-Video!)

I've switch huffduff-video to use S3 URLs on the
`huffduff-video.s3.amazonaws.com`
[virtual host](http://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html)
and added a
[`robots.txt` file](https://github.com/snarfed/huffduff-video/tree/master/s3_robots.txt)
that blocks all bots. Fingers crossed!
