Indie stats

<p class="right third">
 <a href="http://indiewebcamp.com/">
   <img src="/indiewebcamp.png"/></a></p>

When I have to decide whether to implement a feature in
[Bridgy](https://www.brid.gy/), or how to prioritize tasks, I often make
assumptions like _most indie web sites have an h-card_, or
_[PSCs](http://indiewebcamp.com/permashortcitations) and
[PSLs](http://indiewebcamp.com/permashortlinks) never got much traction_. I know
they're based on anecdotal evidence, not actual data, but it's all I have, so I
run with it.

Clearly not ideal. I'd love to use real data instead! Here's a project idea:
crawl indieweb sites and generate usage stats for
[microformats2](http://microformats.org/wiki/microformats2) classes and other
indieweb features.

Straw man design proposal:

* Seed from [IRC_People](http://indiewebcamp.com/IRC_People). Don't
  even bother spidering, at least to start; just crawl those domains.
* Try to identify the server. (Known, WordPress, etc.)
* Parse every h-entry on the front page and every h-feed linked from the front
  page.
* Count all instances of mf2 classes. Identify them by the mf2 prefixes: h-, p-,
  u-, dt-, and e-.
* Aggregate per page and per domain so we can answer questions like _what
  fraction of posts are [photo](http://indiewebcamp.com/photo) posts?_ and _how
  many people use [syndication](http://indiewebcamp.com/rel-syndication) links?_
* Generate a static html report with simple graphs using [D3](http://d3js.org/) or
  [Google Charts](https://developers.google.com/chart/) or whatever.
* Set up a cron job to do all this once a day or so.

Stretch goals:

* Store and report dates for each mf2 class: first seen, last seen, etc., both
  global and per domain.
* Crawl and analyze features in silo posts too, e.g. _[PSCs](http://indiewebcamp.com/permashortcitations)/[PSLs](http://indiewebcamp.com/permashortlinks)_.

<a class="u-syndication" href="http://news.indiewebcamp.com/post/snarfed.org/indie-stats">
  <em>Also on IndieNews.</em></a>
